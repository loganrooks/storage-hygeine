# Architecture Overview

This document provides a high-level overview of the core components within the Storage Hygiene System and how they interact. For a more detailed architectural breakdown, including diagrams and design decisions, please refer to the [Architecture Report](./architecture/architecture_report.md).

## Core Components

The system is composed of several key Python modules located in `src/storage_hygiene/`:

*   **`main.py` (Entry Point):**
    *   **Responsibility:** Orchestrates the overall workflow. Parses command-line arguments, initializes other components, and calls their methods in the correct sequence (config -> scan -> analyze -> execute). Handles top-level error reporting and exit codes.
*   **`config_manager.py` (`ConfigManager`):**
    *   **Responsibility:** Loads, validates, and provides access to configuration settings from the `config.yaml` file. Merges default settings with user-provided configurations. Handles overrides from command-line arguments where applicable (though `main.py` currently handles CLI overrides directly for paths).
*   **`metadata_store.py` (`MetadataStore`):**
    *   **Responsibility:** Manages the persistence layer for file metadata using a DuckDB database. Provides methods to connect to the database, create necessary tables, insert or update file records (`upsert_file_record`), query records based on various criteria (size, age, hash), and update file paths after actions (`update_file_path`).
*   **`scanner.py` (`Scanner`):**
    *   **Responsibility:** Traverses the specified file system directories (`scan_paths` or `--targets`). For each file encountered, it calculates metadata (size, modification time, access time) and a content hash. It interacts with the `MetadataStore` to store or update this information, enabling incremental scans by comparing timestamps. Handles file system errors gracefully (e.g., permission denied).
*   **`analysis_engine.py` (`AnalysisEngine`):**
    *   **Responsibility:** Applies the analysis rules defined in the configuration (`rules` section) to the metadata stored in the `MetadataStore`. It queries the database to find files matching rule criteria (e.g., duplicates based on hash, files exceeding `min_size_mb`, files older than `min_days_unaccessed`). It compiles a list of actions to be taken based on the matched rules and configured `action` for each rule.
*   **`action_executor.py` (`ActionExecutor`):**
    *   **Responsibility:** Takes the list of actions generated by the `AnalysisEngine` and executes them. Currently, this primarily involves moving files to the specified `staging_path` based on the action type (e.g., `stage_duplicate`, `review_large`). It handles the creation of appropriate subdirectories within the staging area. It interacts with the `MetadataStore` to update the path of moved files. Includes a `--dry-run` mode check to only log actions without performing them.

## Interaction Flow

The typical execution flow proceeds as follows:

1.  The user executes `python src/storage_hygiene/main.py` with optional arguments.
2.  `main.py` parses arguments.
3.  `main.py` instantiates `ConfigManager` to load configuration.
4.  `main.py` instantiates `MetadataStore` to connect to the database.
5.  `main.py` instantiates `Scanner`, passing it the `ConfigManager` and `MetadataStore`.
6.  `main.py` calls `Scanner.scan_directory()` for each target path.
    *   `Scanner` walks the directory tree.
    *   For each file, `Scanner` gets stats, calculates hash, and calls `MetadataStore.upsert_file_record()`.
7.  `main.py` instantiates `AnalysisEngine`, passing it the `ConfigManager` and `MetadataStore`.
8.  `main.py` calls `AnalysisEngine.analyze()`.
    *   `AnalysisEngine` reads rules from `ConfigManager`.
    *   `AnalysisEngine` queries `MetadataStore` based on rules.
    *   `AnalysisEngine` returns a dictionary of actions required (e.g., `{ 'stage_duplicate': [{'path': '...', 'hash': '...'}, ...], 'review_large': [...] }`).
9.  `main.py` instantiates `ActionExecutor`, passing it the `ConfigManager` and `MetadataStore`.
10. `main.py` calls `ActionExecutor.execute_actions()` with the analysis results.
    *   `ActionExecutor` checks for `--dry-run`.
    *   For each action, `ActionExecutor` performs the required file operation (e.g., move file to staging path).
    *   If a file is moved, `ActionExecutor` calls `MetadataStore.update_file_path()` to update the database record.

This modular design allows each component to focus on a specific task, making the system easier to understand, test, and maintain.